{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6eMvxFwuX_w"
      },
      "source": [
        "Dataset:\n",
        "https://github.com/IndoNLP/indonlu/tree/master/dataset/nerp_ner-prosa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0nV1uZOHhQZ"
      },
      "source": [
        "Entity:\n",
        "*   PPL (Nama orang): joko widodo, budi gunawan, gus dur, dll.\n",
        "*   PLC (Tempat): dki jakarta, chicago, monas, mata elang international stadium, dll.\n",
        "*   EVT (Kejadian, peristiwa): bandung great sale 2017, kai serba 70, dll.\n",
        "*   IND (nama produk): apple watch, call of duty (game), fifa 16, hainan airlines, dll.\n",
        "*   FNB (makanan): es kopi, sponge cake, dll.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3uEzfpMKm3K"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DIeOp9PKEm_o"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def load_conll_from_url(url: str):\n",
        "    text = requests.get(url).text.strip().split(\"\\n\")\n",
        "\n",
        "    data = []\n",
        "    tokens = []\n",
        "    tags = []\n",
        "\n",
        "    for line in text:\n",
        "        if line.strip() == \"\":\n",
        "            if tokens:\n",
        "                data.append((tokens, tags))\n",
        "                tokens = []\n",
        "                tags = []\n",
        "        else:\n",
        "            parts = line.split()\n",
        "            token, tag = parts[0], parts[-1]\n",
        "            tokens.append(token)\n",
        "            tags.append(tag)\n",
        "\n",
        "    if tokens:\n",
        "        data.append((tokens, tags))\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_conll_from_file(file_path: str):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read().strip().split(\"\\n\")\n",
        "    data = []\n",
        "    tokens = []\n",
        "    tags = []\n",
        "    for line in text:\n",
        "        if line.strip() == \"\":\n",
        "            if tokens:\n",
        "                data.append((tokens, tags))\n",
        "                tokens = []\n",
        "                tags = []\n",
        "        else:\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 2:\n",
        "                token, tag = parts[0], parts[-1]\n",
        "                tokens.append(token)\n",
        "                tags.append(tag)\n",
        "    if tokens:\n",
        "        data.append((tokens, tags))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YmLyfROHim4s"
      },
      "outputs": [],
      "source": [
        "# train_url = \"https://raw.githubusercontent.com/IndoNLP/indonlu/master/dataset/nerp_ner-prosa/train_preprocess.txt\"\n",
        "# valid_url = \"https://raw.githubusercontent.com/IndoNLP/indonlu/master/dataset/nerp_ner-prosa/valid_preprocess.txt\"\n",
        "# test_url  = \"https://raw.githubusercontent.com/IndoNLP/indonlu/master/dataset/nerp_ner-prosa/test_preprocess.txt\"\n",
        "\n",
        "# train_data = load_conll_from_url(train_url)\n",
        "# valid_data = load_conll_from_url(valid_url)\n",
        "# test_data  = load_conll_from_url(test_url)\n",
        "\n",
        "train_data = load_conll_from_file(\"train_fixed_p1.txt\")\n",
        "valid_data = load_conll_from_file(\"valid_fixed_p1.txt\")\n",
        "test_data  = load_conll_from_file(\"test_fixed_p1.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tlh5VVJlyzsH",
        "outputId": "85effe42-a6fe-4487-e9f3-1df4f0464905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAHenjYuzHtD",
        "outputId": "96bc9222-b757-4998-f63a-5cfc74c03e00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-12-30 02:10:16--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.249.182.62, 13.249.182.39, 13.249.182.81, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.249.182.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4507049071 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.id.300.bin.gz’\n",
            "\n",
            "cc.id.300.bin.gz    100%[===================>]   4.20G   245MB/s    in 30s     \n",
            "\n",
            "2025-12-30 02:10:46 (142 MB/s) - ‘cc.id.300.bin.gz’ saved [4507049071/4507049071]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz\n",
        "!gunzip cc.id.300.bin.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM-Fz-OwywQs",
        "outputId": "98af5a39-4453-4789-ab4b-21790e732cc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 18930\n",
            "Number of labels: 11\n",
            "Labels: ['B-EVT', 'B-FNB', 'B-IND', 'B-PLC', 'B-PPL', 'I-EVT', 'I-FNB', 'I-IND', 'I-PLC', 'I-PPL', 'O']\n",
            "Class weights: tensor([1.4321, 2.7364, 0.4863, 0.3411, 0.3089, 0.8704, 3.3835, 0.5331, 0.5242,\n",
            "        0.3726, 0.0115])\n",
            "Embedding matrix shape: torch.Size([18930, 300])\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from collections import Counter\n",
        "import fasttext\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "fasttext_model = fasttext.load_model(\"../cc.id.300.bin\")\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "# Prepare vocabulary and labels\n",
        "def build_vocab(data):\n",
        "    word_counter = Counter()\n",
        "    for tokens, _ in data:\n",
        "        word_counter.update(tokens)\n",
        "\n",
        "    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "    for word, _ in word_counter.most_common():\n",
        "        vocab[word] = len(vocab)\n",
        "\n",
        "    return vocab\n",
        "\n",
        "def build_label_vocab(data):\n",
        "    labels = set()\n",
        "    for _, tags in data:\n",
        "        labels.update(tags)\n",
        "\n",
        "    label_vocab = {label: idx for idx, label in enumerate(sorted(labels))}\n",
        "    return label_vocab\n",
        "\n",
        "vocab = build_vocab(train_data)\n",
        "label_vocab = build_label_vocab(train_data)\n",
        "idx_to_label = {v: k for k, v in label_vocab.items()}\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "print(f\"Number of labels: {len(label_vocab)}\")\n",
        "print(f\"Labels: {list(label_vocab.keys())}\")\n",
        "\n",
        "# Calculate class weights\n",
        "def calculate_class_weights(data, label_vocab):\n",
        "    label_counts = Counter()\n",
        "    for _, tags in data:\n",
        "        label_counts.update(tags)\n",
        "\n",
        "    total = sum(label_counts.values())\n",
        "    weights = torch.zeros(len(label_vocab))\n",
        "\n",
        "    for label, idx in label_vocab.items():\n",
        "        count = label_counts[label]\n",
        "        # Inverse frequency weighting\n",
        "        weights[idx] = total / (len(label_vocab) * count)\n",
        "\n",
        "    # Normalize weights\n",
        "    weights = weights / weights.sum() * len(label_vocab)\n",
        "    return weights\n",
        "\n",
        "class_weights = calculate_class_weights(train_data, label_vocab)\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "# Create embedding matrix\n",
        "def create_embedding_matrix(vocab, fasttext_model, embedding_dim):\n",
        "    embedding_matrix = np.zeros((len(vocab), embedding_dim))\n",
        "\n",
        "    for word, idx in vocab.items():\n",
        "        if word in [\"<PAD>\", \"<UNK>\"]:\n",
        "            continue\n",
        "        try:\n",
        "            embedding_matrix[idx] = fasttext_model[word]\n",
        "        except KeyError:\n",
        "            # Random initialization for OOV words\n",
        "            embedding_matrix[idx] = np.random.normal(0, 0.1, embedding_dim)\n",
        "\n",
        "    return torch.FloatTensor(embedding_matrix)\n",
        "\n",
        "embedding_matrix = create_embedding_matrix(vocab, fasttext_model, EMBEDDING_DIM)\n",
        "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")\n",
        "\n",
        "# Dataset\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, data, vocab, label_vocab):\n",
        "        self.data = data\n",
        "        self.vocab = vocab\n",
        "        self.label_vocab = label_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens, tags = self.data[idx]\n",
        "\n",
        "        token_ids = [self.vocab.get(token, self.vocab[\"<UNK>\"]) for token in tokens]\n",
        "        tag_ids = [self.label_vocab[tag] for tag in tags]\n",
        "\n",
        "        return torch.LongTensor(token_ids), torch.LongTensor(tag_ids)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    tokens, tags = zip(*batch)\n",
        "    lengths = torch.LongTensor([len(t) for t in tokens])\n",
        "\n",
        "    max_len = lengths.max().item()\n",
        "    padded_tokens = torch.zeros(len(tokens), max_len, dtype=torch.long)\n",
        "    padded_tags = torch.zeros(len(tags), max_len, dtype=torch.long)\n",
        "\n",
        "    for i, (token, tag) in enumerate(zip(tokens, tags)):\n",
        "        padded_tokens[i, :len(token)] = token\n",
        "        padded_tags[i, :len(tag)] = tag\n",
        "\n",
        "    return padded_tokens, padded_tags, lengths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b39db73"
      },
      "source": [
        "### Menyimpan `vocab` dan `label_vocab`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "631d7a2f",
        "outputId": "25e4eb2d-4c05-4540-8502-99bd6fe889e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab saved to vocab.pkl\n",
            "Label Vocab saved to label_vocab.pkl\n",
            "idx_to_label saved to idx_to_label.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Menyimpan vocab\n",
        "with open('vocab.pkl', 'wb') as f:\n",
        "    pickle.dump(vocab, f)\n",
        "print(\"Vocab saved to vocab.pkl\")\n",
        "\n",
        "# Menyimpan label_vocab (dan idx_to_label jika diperlukan untuk UI)\n",
        "with open('label_vocab.pkl', 'wb') as f:\n",
        "    pickle.dump(label_vocab, f)\n",
        "print(\"Label Vocab saved to label_vocab.pkl\")\n",
        "\n",
        "with open('idx_to_label.pkl', 'wb') as f:\n",
        "    pickle.dump(idx_to_label, f)\n",
        "print(\"idx_to_label saved to idx_to_label.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2EEEdvgmyEGo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# CRF Layer\n",
        "class CRF(nn.Module):\n",
        "    def __init__(self, num_tags):\n",
        "        super(CRF, self).__init__()\n",
        "        self.num_tags = num_tags\n",
        "\n",
        "        # Transition scores: transitions[i][j] = score of transitioning from tag i to tag j\n",
        "        self.transitions = nn.Parameter(torch.randn(num_tags, num_tags))\n",
        "\n",
        "        # Start and end transitions\n",
        "        self.start_transitions = nn.Parameter(torch.randn(num_tags))\n",
        "        self.end_transitions = nn.Parameter(torch.randn(num_tags))\n",
        "\n",
        "    def forward(self, emissions, tags, mask):\n",
        "        \"\"\"Compute negative log likelihood (for training)\"\"\"\n",
        "        return -self._log_likelihood(emissions, tags, mask)\n",
        "\n",
        "    def _log_likelihood(self, emissions, tags, mask):\n",
        "        batch_size, seq_length, num_tags = emissions.shape\n",
        "\n",
        "        # Compute score of the given tag sequence\n",
        "        score = self._compute_score(emissions, tags, mask)\n",
        "\n",
        "        # Compute partition function (normalization)\n",
        "        partition = self._compute_partition(emissions, mask)\n",
        "\n",
        "        return (score - partition).sum()\n",
        "\n",
        "    def _compute_score(self, emissions, tags, mask):\n",
        "        batch_size, seq_length = tags.shape\n",
        "\n",
        "        score = self.start_transitions[tags[:, 0]]\n",
        "        score += emissions[:, 0].gather(1, tags[:, 0].unsqueeze(1)).squeeze(1)\n",
        "\n",
        "        for i in range(1, seq_length):\n",
        "            mask_i = mask[:, i]\n",
        "            emit_score = emissions[:, i].gather(1, tags[:, i].unsqueeze(1)).squeeze(1)\n",
        "            trans_score = self.transitions[tags[:, i - 1], tags[:, i]]\n",
        "\n",
        "            score += (emit_score + trans_score) * mask_i\n",
        "\n",
        "        last_tags = tags.gather(1, mask.sum(1).long().unsqueeze(1) - 1).squeeze(1)\n",
        "        score += self.end_transitions[last_tags]\n",
        "\n",
        "        return score\n",
        "\n",
        "    def _compute_partition(self, emissions, mask):\n",
        "        batch_size, seq_length, num_tags = emissions.shape\n",
        "\n",
        "        alpha = self.start_transitions + emissions[:, 0]\n",
        "\n",
        "        for i in range(1, seq_length):\n",
        "            emit_score = emissions[:, i].unsqueeze(1)\n",
        "            trans_score = self.transitions.unsqueeze(0)\n",
        "            next_alpha = alpha.unsqueeze(2) + emit_score + trans_score\n",
        "            next_alpha = torch.logsumexp(next_alpha, dim=1)\n",
        "\n",
        "            mask_i = mask[:, i].unsqueeze(1)\n",
        "            alpha = next_alpha * mask_i + alpha * (1 - mask_i)\n",
        "\n",
        "        alpha += self.end_transitions\n",
        "        return torch.logsumexp(alpha, dim=1)\n",
        "\n",
        "    def decode(self, emissions, mask):\n",
        "        \"\"\"Viterbi decoding\"\"\"\n",
        "        batch_size, seq_length, num_tags = emissions.shape\n",
        "\n",
        "        viterbi_score = self.start_transitions + emissions[:, 0]\n",
        "        viterbi_path = []\n",
        "\n",
        "        for i in range(1, seq_length):\n",
        "            broadcast_score = viterbi_score.unsqueeze(2)\n",
        "            broadcast_emission = emissions[:, i].unsqueeze(1)\n",
        "            next_score = broadcast_score + self.transitions + broadcast_emission\n",
        "\n",
        "            next_score, indices = next_score.max(dim=1)\n",
        "            viterbi_path.append(indices)\n",
        "\n",
        "            mask_i = mask[:, i].unsqueeze(1)\n",
        "            viterbi_score = next_score * mask_i + viterbi_score * (1 - mask_i)\n",
        "\n",
        "        viterbi_score += self.end_transitions\n",
        "        _, best_last_tag = viterbi_score.max(dim=1)\n",
        "\n",
        "        # Backtrack\n",
        "        best_paths = [best_last_tag]\n",
        "        for indices in reversed(viterbi_path):\n",
        "            best_last_tag = indices.gather(1, best_last_tag.unsqueeze(1)).squeeze(1)\n",
        "            best_paths.append(best_last_tag)\n",
        "\n",
        "        best_paths.reverse()\n",
        "        return torch.stack(best_paths, dim=1)\n",
        "\n",
        "# BiGRU-CRF Model\n",
        "class BiGRUCRF(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_tags, embedding_matrix=None):\n",
        "        super(BiGRUCRF, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(embedding_matrix)\n",
        "\n",
        "        self.bigru = nn.GRU(\n",
        "            embedding_dim,\n",
        "            hidden_dim // 2,  # Divide by 2 because bidirectional\n",
        "            num_layers=2,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=0.3\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, num_tags)\n",
        "        self.crf = CRF(num_tags)\n",
        "\n",
        "    def forward(self, x, tags, lengths):\n",
        "        mask = (x != 0).float()\n",
        "\n",
        "        embeddings = self.embedding(x)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "\n",
        "        # Pack padded sequence\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            embeddings, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        gru_out, _ = self.bigru(packed)\n",
        "        gru_out, _ = nn.utils.rnn.pad_packed_sequence(gru_out, batch_first=True)\n",
        "\n",
        "        gru_out = self.dropout(gru_out)\n",
        "        emissions = self.hidden2tag(gru_out)\n",
        "\n",
        "        loss = self.crf(emissions, tags, mask)\n",
        "        return loss\n",
        "\n",
        "    def predict(self, x, lengths):\n",
        "        mask = (x != 0).float()\n",
        "\n",
        "        embeddings = self.embedding(x)\n",
        "\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            embeddings, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        gru_out, _ = self.bigru(packed)\n",
        "        gru_out, _ = nn.utils.rnn.pad_packed_sequence(gru_out, batch_first=True)\n",
        "\n",
        "        emissions = self.hidden2tag(gru_out)\n",
        "        predictions = self.crf.decode(emissions, mask)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F-_bV3sW0NwW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = NERDataset(train_data, vocab, label_vocab)\n",
        "valid_dataset = NERDataset(valid_data, vocab, label_vocab)\n",
        "test_dataset = NERDataset(test_data, vocab, label_vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBQILOB40MRa",
        "outputId": "f459a71a-33a9-436b-c5d4-8581d5ec500f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "==================================================\n",
            "Starting Training\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:14<00:00, 14.34it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 71.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "Train Loss: 416.9869\n",
            "Validation F1: 0.9120\n",
            "✓ Model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:13<00:00, 15.98it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 74.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/20\n",
            "Train Loss: 145.3883\n",
            "Validation F1: 0.9347\n",
            "✓ Model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.24it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 73.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/20\n",
            "Train Loss: 91.3668\n",
            "Validation F1: 0.9370\n",
            "✓ Model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:13<00:00, 16.15it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 51.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/20\n",
            "Train Loss: 65.7185\n",
            "Validation F1: 0.9391\n",
            "✓ Model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:13<00:00, 15.82it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 75.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/20\n",
            "Train Loss: 52.5390\n",
            "Validation F1: 0.9372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.31it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 74.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/20\n",
            "Train Loss: 43.7045\n",
            "Validation F1: 0.9383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:13<00:00, 15.74it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 76.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/20\n",
            "Train Loss: 36.6652\n",
            "Validation F1: 0.9400\n",
            "✓ Model saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:13<00:00, 15.02it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 75.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/20\n",
            "Train Loss: 32.0967\n",
            "Validation F1: 0.9387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.26it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 75.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/20\n",
            "Train Loss: 28.7061\n",
            "Validation F1: 0.9387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.59it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 72.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/20\n",
            "Train Loss: 26.0248\n",
            "Validation F1: 0.9399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.61it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 76.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11/20\n",
            "Train Loss: 22.8964\n",
            "Validation F1: 0.9392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.60it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 75.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12/20\n",
            "Train Loss: 21.0659\n",
            "Validation F1: 0.9380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.57it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 54.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 13/20\n",
            "Train Loss: 20.1860\n",
            "Validation F1: 0.9385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.18it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 74.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 14/20\n",
            "Train Loss: 18.4187\n",
            "Validation F1: 0.9385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.59it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 76.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 15/20\n",
            "Train Loss: 17.5709\n",
            "Validation F1: 0.9399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.42it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 76.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 16/20\n",
            "Train Loss: 16.8665\n",
            "Validation F1: 0.9384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.57it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 74.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 17/20\n",
            "Train Loss: 15.1937\n",
            "Validation F1: 0.9371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.60it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 76.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 18/20\n",
            "Train Loss: 14.7355\n",
            "Validation F1: 0.9396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.50it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 72.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 19/20\n",
            "Train Loss: 15.5839\n",
            "Validation F1: 0.9378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:12<00:00, 16.48it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 74.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 20/20\n",
            "Train Loss: 14.0684\n",
            "Validation F1: 0.9386\n",
            "\n",
            "==================================================\n",
            "Evaluating on Test Set\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 74.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-EVT     0.6200    0.4662    0.5322       133\n",
            "       B-FNB     0.8302    0.5714    0.6769        77\n",
            "       B-IND     0.7828    0.7664    0.7745       381\n",
            "       B-PLC     0.8725    0.7935    0.8311       552\n",
            "       B-PPL     0.8851    0.8309    0.8571       621\n",
            "       I-EVT     0.5369    0.4020    0.4598       199\n",
            "       I-FNB     0.8158    0.4429    0.5741        70\n",
            "       I-IND     0.7291    0.6854    0.7066       267\n",
            "       I-PLC     0.7513    0.6463    0.6948       229\n",
            "       I-PPL     0.8632    0.7995    0.8301       379\n",
            "           O     0.9662    0.9838    0.9749     17044\n",
            "\n",
            "    accuracy                         0.9455     19952\n",
            "   macro avg     0.7866    0.6717    0.7193     19952\n",
            "weighted avg     0.9423    0.9455    0.9432     19952\n",
            "\n",
            "\n",
            "Per-Entity Metrics:\n",
            "B-EVT: F1 = 0.5322\n",
            "B-FNB: F1 = 0.6769\n",
            "B-IND: F1 = 0.7745\n",
            "B-PLC: F1 = 0.8311\n",
            "B-PPL: F1 = 0.8571\n",
            "I-EVT: F1 = 0.4598\n",
            "I-FNB: F1 = 0.5741\n",
            "I-IND: F1 = 0.7066\n",
            "I-PLC: F1 = 0.6948\n",
            "I-PPL: F1 = 0.8301\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = BiGRUCRF(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=256,\n",
        "    num_tags=len(label_vocab),\n",
        "    embedding_matrix=embedding_matrix\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for tokens, tags, lengths in tqdm(loader, desc=\"Training\"):\n",
        "        tokens, tags = tokens.to(device), tags.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(tokens, tags, lengths)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, loader, device, idx_to_label):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for tokens, tags, lengths in tqdm(loader, desc=\"Evaluating\"):\n",
        "            tokens = tokens.to(device)\n",
        "\n",
        "            predictions = model.predict(tokens, lengths)\n",
        "\n",
        "            for i, length in enumerate(lengths):\n",
        "                pred = predictions[i, :length].cpu().numpy()\n",
        "                true = tags[i, :length].numpy()\n",
        "\n",
        "                all_preds.extend([idx_to_label[p] for p in pred])\n",
        "                all_labels.extend([idx_to_label[t] for t in true])\n",
        "\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "best_f1 = 0\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Starting Training\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_preds, val_labels = evaluate(model, valid_loader, device, idx_to_label)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
        "\n",
        "    scheduler.step(train_loss)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Validation F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "        print(\"✓ Model saved!\")\n",
        "\n",
        "# Load best model and evaluate on test set\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Evaluating on Test Set\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "test_preds, test_labels = evaluate(model, test_loader, device, idx_to_label)\n",
        "\n",
        "print(\"\\nTest Set Results:\")\n",
        "print(classification_report(test_labels, test_preds, digits=4))\n",
        "\n",
        "# Calculate per-entity F1 scores\n",
        "print(\"\\nPer-Entity Metrics:\")\n",
        "unique_labels = sorted(set(test_labels))\n",
        "for label in unique_labels:\n",
        "    if label != 'O':\n",
        "        label_preds = [1 if p == label else 0 for p in test_preds]\n",
        "        label_true = [1 if t == label else 0 for t in test_labels]\n",
        "        f1 = f1_score(label_true, label_preds)\n",
        "        print(f\"{label}: F1 = {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8UEOZUa1b01",
        "outputId": "e7c62707-e365-4cdf-97fb-257f42181ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "\n",
            "==================================================\n",
            "Starting Training\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:42<00:00,  4.92it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 31.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "Train Loss: 447.6979\n",
            "Validation F1: 0.9033\n",
            "✓ Model saved! (Best F1: 0.9033)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:41<00:00,  5.09it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 30.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/20\n",
            "Train Loss: 157.4314\n",
            "Validation F1: 0.9304\n",
            "✓ Model saved! (Best F1: 0.9304)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:42<00:00,  4.90it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 29.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/20\n",
            "Train Loss: 98.4736\n",
            "Validation F1: 0.9323\n",
            "✓ Model saved! (Best F1: 0.9323)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:44<00:00,  4.77it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 34.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/20\n",
            "Train Loss: 70.2894\n",
            "Validation F1: 0.9339\n",
            "✓ Model saved! (Best F1: 0.9339)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:42<00:00,  4.90it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 35.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/20\n",
            "Train Loss: 55.4094\n",
            "Validation F1: 0.9358\n",
            "✓ Model saved! (Best F1: 0.9358)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:39<00:00,  5.27it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 35.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/20\n",
            "Train Loss: 44.9656\n",
            "Validation F1: 0.9324\n",
            "No improvement. Patience: 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:39<00:00,  5.26it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 36.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/20\n",
            "Train Loss: 37.1480\n",
            "Validation F1: 0.9360\n",
            "✓ Model saved! (Best F1: 0.9360)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:40<00:00,  5.19it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 35.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/20\n",
            "Train Loss: 34.2499\n",
            "Validation F1: 0.9356\n",
            "No improvement. Patience: 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:40<00:00,  5.23it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 38.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/20\n",
            "Train Loss: 29.3732\n",
            "Validation F1: 0.9351\n",
            "No improvement. Patience: 2/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:37<00:00,  5.58it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 33.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/20\n",
            "Train Loss: 25.5699\n",
            "Validation F1: 0.9361\n",
            "✓ Model saved! (Best F1: 0.9361)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:40<00:00,  5.16it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 29.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11/20\n",
            "Train Loss: 23.8352\n",
            "Validation F1: 0.9344\n",
            "No improvement. Patience: 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:42<00:00,  4.98it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 34.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12/20\n",
            "Train Loss: 21.4949\n",
            "Validation F1: 0.9348\n",
            "No improvement. Patience: 2/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 210/210 [00:39<00:00,  5.25it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 33.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 13/20\n",
            "Train Loss: 19.8763\n",
            "Validation F1: 0.9348\n",
            "No improvement. Patience: 3/3\n",
            "\n",
            "⚠ Early stopping triggered after 13 epochs\n",
            "Best Validation F1: 0.9361\n",
            "\n",
            "==================================================\n",
            "Evaluating on Test Set\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 32.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-EVT     0.5259    0.5182    0.5221       137\n",
            "       B-FNB     0.7576    0.6494    0.6993        77\n",
            "       B-IND     0.7842    0.7493    0.7664       383\n",
            "       B-PLC     0.8426    0.8213    0.8318       554\n",
            "       B-PPL     0.8283    0.8429    0.8356       624\n",
            "       I-EVT     0.5463    0.5385    0.5424       208\n",
            "       I-FNB     0.8281    0.6092    0.7020        87\n",
            "       I-IND     0.7193    0.7193    0.7193       342\n",
            "       I-PLC     0.7709    0.7709    0.7709       358\n",
            "       I-PPL     0.8276    0.8460    0.8367       539\n",
            "           O     0.9713    0.9740    0.9727     16643\n",
            "\n",
            "    accuracy                         0.9394     19952\n",
            "   macro avg     0.7638    0.7308    0.7454     19952\n",
            "weighted avg     0.9389    0.9394    0.9391     19952\n",
            "\n",
            "\n",
            "Per-Entity Metrics:\n",
            "B-EVT: F1 = 0.5221\n",
            "B-FNB: F1 = 0.6993\n",
            "B-IND: F1 = 0.7664\n",
            "B-PLC: F1 = 0.8318\n",
            "B-PPL: F1 = 0.8356\n",
            "I-EVT: F1 = 0.5424\n",
            "I-FNB: F1 = 0.7020\n",
            "I-IND: F1 = 0.7193\n",
            "I-PLC: F1 = 0.7709\n",
            "I-PPL: F1 = 0.8367\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = BiGRUCRF(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=256,\n",
        "    num_tags=len(label_vocab),\n",
        "    embedding_matrix=embedding_matrix\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for tokens, tags, lengths in tqdm(loader, desc=\"Training\"):\n",
        "        tokens, tags = tokens.to(device), tags.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(tokens, tags, lengths)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, loader, device, idx_to_label):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for tokens, tags, lengths in tqdm(loader, desc=\"Evaluating\"):\n",
        "            tokens = tokens.to(device)\n",
        "\n",
        "            predictions = model.predict(tokens, lengths)\n",
        "\n",
        "            for i, length in enumerate(lengths):\n",
        "                pred = predictions[i, :length].cpu().numpy()\n",
        "                true = tags[i, :length].numpy()\n",
        "\n",
        "                all_preds.extend([idx_to_label[p] for p in pred])\n",
        "                all_labels.extend([idx_to_label[t] for t in true])\n",
        "\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Training loop with Early Stopping\n",
        "num_epochs = 20\n",
        "best_f1 = 0\n",
        "patience = 3  # Early stopping patience\n",
        "patience_counter = 0\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Starting Training\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_preds, val_labels = evaluate(model, valid_loader, device, idx_to_label)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
        "\n",
        "    scheduler.step(train_loss)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Validation F1: {val_f1:.4f}\")\n",
        "\n",
        "    # Early stopping logic\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "        print(f\"✓ Model saved! (Best F1: {best_f1:.4f})\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"No improvement. Patience: {patience_counter}/{patience}\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\n⚠ Early stopping triggered after {epoch + 1} epochs\")\n",
        "            print(f\"Best Validation F1: {best_f1:.4f}\")\n",
        "            break\n",
        "\n",
        "# Load best model and evaluate on test set\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Evaluating on Test Set\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "test_preds, test_labels = evaluate(model, test_loader, device, idx_to_label)\n",
        "\n",
        "print(\"\\nTest Set Results:\")\n",
        "print(classification_report(test_labels, test_preds, digits=4))\n",
        "\n",
        "# Calculate per-entity F1 scores\n",
        "print(\"\\nPer-Entity Metrics:\")\n",
        "unique_labels = sorted(set(test_labels))\n",
        "for label in unique_labels:\n",
        "    if label != 'O':\n",
        "        label_preds = [1 if p == label else 0 for p in test_preds]\n",
        "        label_true = [1 if t == label else 0 for t in test_labels]\n",
        "        f1 = f1_score(label_true, label_preds)\n",
        "        print(f\"{label}: F1 = {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e24Efy1U2YzG",
        "outputId": "d82a5dad-d7eb-425d-bd3c-4b35fa0afb72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BiGRUCRF(\n",
              "  (embedding): Embedding(18930, 300, padding_idx=0)\n",
              "  (bigru): GRU(300, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (hidden2tag): Linear(in_features=256, out_features=11, bias=True)\n",
              "  (crf): CRF()\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "\n",
            "==================================================\n",
            "Evaluating on Test Set (Excluding 'O' tags)\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 27/27 [00:00<00:00, 29.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set Results (Entity-level metrics):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-EVT     0.5259    0.5182    0.5221       137\n",
            "       B-FNB     0.7576    0.6494    0.6993        77\n",
            "       B-IND     0.7842    0.7493    0.7664       383\n",
            "       B-PLC     0.8426    0.8213    0.8318       554\n",
            "       B-PPL     0.8283    0.8429    0.8356       624\n",
            "       I-EVT     0.5463    0.5385    0.5424       208\n",
            "       I-FNB     0.8281    0.6092    0.7020        87\n",
            "       I-IND     0.7193    0.7193    0.7193       342\n",
            "       I-PLC     0.7709    0.7709    0.7709       358\n",
            "       I-PPL     0.8276    0.8460    0.8367       539\n",
            "\n",
            "   micro avg     0.7762    0.7652    0.7707      3309\n",
            "   macro avg     0.7431    0.7065    0.7226      3309\n",
            "weighted avg     0.7761    0.7652    0.7700      3309\n",
            "\n",
            "\n",
            "==================================================\n",
            "Seqeval Metrics\n",
            "==================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         EVT     0.4632    0.4599    0.4615       137\n",
            "         FNB     0.6377    0.5714    0.6027        77\n",
            "         IND     0.6624    0.6815    0.6718       383\n",
            "         PLC     0.7870    0.7671    0.7770       554\n",
            "         PPL     0.7997    0.8189    0.8092       624\n",
            "\n",
            "   micro avg     0.7334    0.7346    0.7340      1775\n",
            "   macro avg     0.6700    0.6598    0.6644      1775\n",
            "weighted avg     0.7331    0.7346    0.7337      1775\n",
            "\n",
            "\n",
            "Overall F1 (seqeval): 0.7340\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = BiGRUCRF(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=256,\n",
        "    num_tags=len(label_vocab),\n",
        "    embedding_matrix=embedding_matrix\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for tokens, tags, lengths in tqdm(loader, desc=\"Training\"):\n",
        "        tokens, tags = tokens.to(device), tags.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(tokens, tags, lengths)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# Evaluation function - exclude 'O' tags\n",
        "def evaluate(model, loader, device, idx_to_label):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for tokens, tags, lengths in tqdm(loader, desc=\"Evaluating\"):\n",
        "            tokens = tokens.to(device)\n",
        "\n",
        "            predictions = model.predict(tokens, lengths)\n",
        "\n",
        "            for i, length in enumerate(lengths):\n",
        "                pred = predictions[i, :length].cpu().numpy()\n",
        "                true = tags[i, :length].numpy()\n",
        "\n",
        "                # Filter out 'O' tags\n",
        "                for p, t in zip(pred, true):\n",
        "                    pred_label = idx_to_label[p]\n",
        "                    true_label = idx_to_label[t]\n",
        "\n",
        "                    # Only include non-O predictions\n",
        "                    if true_label != 'O' or pred_label != 'O':\n",
        "                        all_preds.append(pred_label)\n",
        "                        all_labels.append(true_label)\n",
        "\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Load best model and evaluate on test set\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Evaluating on Test Set (Excluding 'O' tags)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "checkpoint = torch.load('best_model.pt', map_location=device)\n",
        "model.load_state_dict(checkpoint)\n",
        "test_preds, test_labels = evaluate(model, test_loader, device, idx_to_label)\n",
        "\n",
        "# Filter labels for classification report (exclude 'O' from label list)\n",
        "entity_labels = [label for label in sorted(set(test_labels)) if label != 'O']\n",
        "\n",
        "print(\"\\nTest Set Results (Entity-level metrics):\")\n",
        "print(classification_report(\n",
        "    test_labels,\n",
        "    test_preds,\n",
        "    labels=entity_labels,  # Only evaluate on entity labels\n",
        "    digits=4\n",
        "))\n",
        "\n",
        "# Alternative: Use seqeval library (recommended for NER)\n",
        "# pip install seqeval\n",
        "from seqeval.metrics import classification_report as seq_report\n",
        "from seqeval.metrics import f1_score as seq_f1\n",
        "\n",
        "# Group predictions by sentence for seqeval\n",
        "def group_by_sentence(preds, labels, loader, idx_to_label):\n",
        "    \"\"\"Group token predictions back into sentences\"\"\"\n",
        "    all_pred_tags = []\n",
        "    all_true_tags = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for tokens, tags, lengths in loader:\n",
        "            tokens = tokens.to(device)\n",
        "            predictions = model.predict(tokens, lengths)\n",
        "\n",
        "            for i, length in enumerate(lengths):\n",
        "                pred_seq = [idx_to_label[p] for p in predictions[i, :length].cpu().numpy()]\n",
        "                true_seq = [idx_to_label[t] for t in tags[i, :length].numpy()]\n",
        "\n",
        "                all_pred_tags.append(pred_seq)\n",
        "                all_true_tags.append(true_seq)\n",
        "\n",
        "    return all_pred_tags, all_true_tags\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Seqeval Metrics\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "pred_tags, true_tags = group_by_sentence(test_preds, test_labels, test_loader, idx_to_label)\n",
        "print(seq_report(true_tags, pred_tags, digits=4))\n",
        "print(f\"\\nOverall F1 (seqeval): {seq_f1(true_tags, pred_tags):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5G-EP742ZE1",
        "outputId": "2e9c95f1-81ba-4712-9f27-c417f0c8f33b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Contoh Data Asli vs Prediksi\n",
            "==================================================\n",
            "\n",
            "--- Contoh 1 ---\n",
            "Tokens:      kuasa hukum teamster berasal dari edmonton , namun tinggal di sekitar vancouver sejak tahun 1991 .\n",
            "True Labels: ['O', 'O', 'B-PPL', 'O', 'O', 'B-PLC', 'O', 'O', 'O', 'O', 'O', 'B-PLC', 'O', 'O', 'O', 'O']\n",
            "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PLC', 'O', 'O', 'O', 'O']\n",
            "\n",
            "--- Contoh 2 ---\n",
            "Tokens:      data diurutkan berdasarkan umur , jenis kelamin dan metode ; pertambahan yang ditandai terlihat di antara orang skotlandia berumur dari 25 sampai 54 tahun dengan gantung diri meningkatkan popularitas .\n",
            "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PLC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PLC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "--- Contoh 3 ---\n",
            "Tokens:      \" urusan dengan atasannya masuk dalam aturan pelanggaran uu kepegawaian dan etika . presiden sebagai atasan punya hak untuk beri sanksi, \" kata yesmil , saat dihubungi wartawan , jumat ( 6/4) .\n",
            "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PPL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PPL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "--- Contoh 4 ---\n",
            "Tokens:      \" saya pikir itu pembicaraan publik , di era demokrasi ini kan orang bebas berbicara apa saja . tapi kita di kabinet biasa . presiden dengan menteri - menterinya biasa, \" tandas segaf .\n",
            "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PPL', 'O']\n",
            "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PPL', 'O']\n",
            "\n",
            "--- Contoh 5 ---\n",
            "Tokens:      sebagian besar ahli industri tetap skeptis dan takut jika program nya akan memakan biaya besar dan sulit ditangani dan menghasilkan kemajuan komersial yang tidak nyata .\n",
            "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Contoh Data Asli vs Prediksi\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "num_examples_to_show = 5 # Number of examples to display\n",
        "\n",
        "# test_preds is a flattened list of all predicted labels.\n",
        "# We need to re-segment it by sentence length.\n",
        "current_preds_idx = 0\n",
        "\n",
        "for i in range(num_examples_to_show):\n",
        "    tokens, true_labels_raw = test_data[i] # true_labels_raw already contains string labels\n",
        "    sentence_length = len(tokens)\n",
        "\n",
        "    # Get predicted labels for the current sentence\n",
        "    predicted_labels = test_preds[current_preds_idx : current_preds_idx + sentence_length]\n",
        "\n",
        "    print(f\"\\n--- Contoh {i+1} ---\")\n",
        "    print(f\"Tokens:      {' '.join(tokens)}\")\n",
        "    print(f\"True Labels: {true_labels_raw}\") # Use true_labels_raw directly\n",
        "    print(f\"Pred Labels: {predicted_labels}\")\n",
        "\n",
        "    current_preds_idx += sentence_length # Update index for the next sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb5jd1nuG3Ad",
        "outputId": "c2ffd53c-ca00-430a-a58f-e931e5057e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded vocab size: 18930\n",
            "Loaded label vocab size: 11\n",
            "Loaded idx_to_label keys: [0, 1, 2, 3, 4]...\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Memuat vocab\n",
        "with open('vocab.pkl', 'rb') as f:\n",
        "    loaded_vocab = pickle.load(f)\n",
        "print(f\"Loaded vocab size: {len(loaded_vocab)}\")\n",
        "\n",
        "# Memuat label_vocab\n",
        "with open('label_vocab.pkl', 'rb') as f:\n",
        "    loaded_label_vocab = pickle.load(f)\n",
        "print(f\"Loaded label vocab size: {len(loaded_label_vocab)}\")\n",
        "\n",
        "# Memuat idx_to_label\n",
        "with open('idx_to_label.pkl', 'rb') as f:\n",
        "    loaded_idx_to_label = pickle.load(f)\n",
        "print(f\"Loaded idx_to_label keys: {list(loaded_idx_to_label.keys())[:5]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ8qKMdCFPK_",
        "outputId": "26968624-0abf-40ca-8356-33b6e51d5566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CPU\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating embedding matrix...\n",
            "Embedding matrix shape: torch.Size([18930, 300])\n",
            "Initializing model...\n",
            "Loading model weights...\n",
            "✓ Model loaded successfully on cpu\n",
            "  - Vocabulary size: 18930\n",
            "  - Label vocabulary size: 11\n",
            "  - Embedding dimension: 300\n",
            "  - Hidden dimension: 256\n"
          ]
        }
      ],
      "source": [
        "import fasttext\n",
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "device = torch.device('cpu')\n",
        "print(\"Using CPU\")\n",
        "\n",
        "fasttext_model = fasttext.load_model(\"../cc.id.300.bin\")\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "def create_embedding_matrix(vocab, fasttext_model, embedding_dim):\n",
        "    \"\"\"\n",
        "    Membuat embedding matrix dari vocabulary dan fasttext model\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((len(vocab), embedding_dim))\n",
        "    \n",
        "    for word, idx in vocab.items():\n",
        "        # Skip special tokens\n",
        "        if word in [\"<PAD>\", \"<UNK>\"]:\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            embedding_matrix[idx] = fasttext_model[word]\n",
        "        except KeyError:\n",
        "            # Random initialization untuk OOV words\n",
        "            embedding_matrix[idx] = np.random.normal(0, 0.1, embedding_dim)\n",
        "    \n",
        "    # Convert ke torch tensor dengan tipe float32\n",
        "    return torch.tensor(embedding_matrix, dtype=torch.float32)\n",
        "\n",
        "print(\"Creating embedding matrix...\")\n",
        "loaded_embedding_matrix = create_embedding_matrix(\n",
        "    loaded_vocab, \n",
        "    fasttext_model, \n",
        "    EMBEDDING_DIM\n",
        ")\n",
        "print(f\"Embedding matrix shape: {loaded_embedding_matrix.shape}\")\n",
        "\n",
        "print(\"Initializing model...\")\n",
        "model = BiGRUCRF(\n",
        "    vocab_size=len(loaded_vocab),\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=256,\n",
        "    num_tags=len(loaded_label_vocab),\n",
        "    embedding_matrix=loaded_embedding_matrix\n",
        ").to(device)\n",
        "\n",
        "print(\"Loading model weights...\")\n",
        "checkpoint = torch.load('best_model.pt', map_location=device)\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print(f\"✓ Model loaded successfully on {device}\")\n",
        "print(f\"  - Vocabulary size: {len(loaded_vocab)}\")\n",
        "print(f\"  - Label vocabulary size: {len(loaded_label_vocab)}\")\n",
        "print(f\"  - Embedding dimension: {EMBEDDING_DIM}\")\n",
        "print(f\"  - Hidden dimension: 256\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpl9hdrE54-J",
        "outputId": "f8609893-be1c-4257-ca32-3911b9a0c81d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Input Sentence: Joko Widodo bertemu dengan Menteri Keuangan Sri Mulyani di Jakarta.\n",
            "Tokens:         ['joko', 'widodo', 'bertemu', 'dengan', 'menteri', 'keuangan', 'sri', 'mulyani', 'di', 'jakarta', '.']\n",
            "Predicted Tags: ['B-PPL', 'I-PPL', 'O', 'O', 'O', 'O', 'B-PPL', 'I-PPL', 'O', 'B-PLC', 'O']\n",
            "\n",
            "Input Sentence: Saya suka makan nasi goreng di restoran Padang.\n",
            "Tokens:         ['saya', 'suka', 'makan', 'nasi', 'goreng', 'di', 'restoran', 'padang', '.']\n",
            "Predicted Tags: ['O', 'O', 'O', 'B-FNB', 'I-FNB', 'O', 'B-PLC', 'I-PLC', 'O']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    # lowercase\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # beri spasi di sekitar simbol\n",
        "    sentence = re.sub(r\"([.,!?():;])\", r\" \\1 \", sentence)\n",
        "\n",
        "    # hapus spasi berlebih\n",
        "    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n",
        "\n",
        "    # tokenisasi\n",
        "    tokens = sentence.split()\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def predict_sentence(sentence, model, vocab, idx_to_label, device):\n",
        "    model.eval()\n",
        "    tokens = preprocess_sentence(sentence)\n",
        "\n",
        "    # Convert tokens to IDs\n",
        "    token_ids = [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens]\n",
        "    token_tensor = torch.LongTensor(token_ids).unsqueeze(0).to(device)\n",
        "    length_tensor = torch.LongTensor([len(tokens)])\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        predictions = model.predict(token_tensor, length_tensor)\n",
        "\n",
        "    # Convert predicted IDs back to labels\n",
        "    predicted_tag_ids = predictions.squeeze(0).cpu().numpy()\n",
        "    predicted_labels = [idx_to_label[tag_id] for tag_id in predicted_tag_ids]\n",
        "\n",
        "    return tokens, predicted_labels\n",
        "\n",
        "# Example usage:\n",
        "user_input_sentence = \"Joko Widodo bertemu dengan Menteri Keuangan Sri Mulyani di Jakarta.\"\n",
        "predicted_tokens, predicted_tags = predict_sentence(user_input_sentence, model, loaded_vocab, loaded_idx_to_label, device)\n",
        "\n",
        "print(f\"\\nInput Sentence: {user_input_sentence}\")\n",
        "print(f\"Tokens:         {predicted_tokens}\")\n",
        "print(f\"Predicted Tags: {predicted_tags}\")\n",
        "\n",
        "user_input_sentence_2 = \"Saya suka makan nasi goreng di restoran Padang.\"\n",
        "predicted_tokens_2, predicted_tags_2 = predict_sentence(user_input_sentence_2, model, loaded_vocab, loaded_idx_to_label, device)\n",
        "\n",
        "print(f\"\\nInput Sentence: {user_input_sentence_2}\")\n",
        "print(f\"Tokens:         {predicted_tokens_2}\")\n",
        "print(f\"Predicted Tags: {predicted_tags_2}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
